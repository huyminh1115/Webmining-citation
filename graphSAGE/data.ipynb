{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Index</th>\n",
       "      <th>References</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OQL[C++]: Extending C++ with an Object Query C...</td>\n",
       "      <td>José A. Blakeley</td>\n",
       "      <td>1995</td>\n",
       "      <td>Modern Database Systems</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transaction Management in Multidatabase Systems.</td>\n",
       "      <td>Yuri Breitbart,Hector Garcia-Molina,Abraham Si...</td>\n",
       "      <td>1995</td>\n",
       "      <td>Modern Database Systems</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overview of the ADDS System.</td>\n",
       "      <td>Yuri Breitbart,Tom C. Reyes</td>\n",
       "      <td>1995</td>\n",
       "      <td>Modern Database Systems</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multimedia Information Systems: Issues and App...</td>\n",
       "      <td>Stavros Christodoulakis,Leonidas Koveos</td>\n",
       "      <td>1995</td>\n",
       "      <td>Modern Database Systems</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Active Database Systems.</td>\n",
       "      <td>Umeshwar Dayal,Eric N. Hanson,Jennifer Widom</td>\n",
       "      <td>1995</td>\n",
       "      <td>Modern Database Systems</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  OQL[C++]: Extending C++ with an Object Query C...   \n",
       "1   Transaction Management in Multidatabase Systems.   \n",
       "2                       Overview of the ADDS System.   \n",
       "3  Multimedia Information Systems: Issues and App...   \n",
       "4                           Active Database Systems.   \n",
       "\n",
       "                                             Authors  Year  \\\n",
       "0                                   José A. Blakeley  1995   \n",
       "1  Yuri Breitbart,Hector Garcia-Molina,Abraham Si...  1995   \n",
       "2                        Yuri Breitbart,Tom C. Reyes  1995   \n",
       "3            Stavros Christodoulakis,Leonidas Koveos  1995   \n",
       "4       Umeshwar Dayal,Eric N. Hanson,Jennifer Widom  1995   \n",
       "\n",
       "                     Venue  Index References Abstract  \n",
       "0  Modern Database Systems      0        NaN      NaN  \n",
       "1  Modern Database Systems      1        NaN      NaN  \n",
       "2  Modern Database Systems      2        NaN      NaN  \n",
       "3  Modern Database Systems      3        NaN      NaN  \n",
       "4  Modern Database Systems      4        NaN      NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"citation-cooked.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Index</th>\n",
       "      <th>References</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An engine fault diagnosis system using intake ...</td>\n",
       "      <td>Jian-Da Wu,Cheng-Kai Huang</td>\n",
       "      <td>2011</td>\n",
       "      <td>Expert Syst. Appl.</td>\n",
       "      <td>1492668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The acceptance and use of customer relationshi...</td>\n",
       "      <td>Jung-Chi Pai,Fu-Ming Tu</td>\n",
       "      <td>2011</td>\n",
       "      <td>Expert Syst. Appl.</td>\n",
       "      <td>1492669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Two-stage structural damage detection using fu...</td>\n",
       "      <td>Shao-Fei Jiang,Chun-Ming Zhang,Shuai Zhang</td>\n",
       "      <td>2011</td>\n",
       "      <td>Expert Syst. Appl.</td>\n",
       "      <td>1492654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A modular Decision Support System for optimum ...</td>\n",
       "      <td>Kaveh Khalili Damghani,Soheil Sadi-Nezhad,M. B...</td>\n",
       "      <td>2011</td>\n",
       "      <td>Expert Syst. Appl.</td>\n",
       "      <td>1492655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Introduction of evidential contribution measur...</td>\n",
       "      <td>Malcolm J. Beynon,Rhys Andrews</td>\n",
       "      <td>2011</td>\n",
       "      <td>Expert Syst. Appl.</td>\n",
       "      <td>1492656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  An engine fault diagnosis system using intake ...   \n",
       "1  The acceptance and use of customer relationshi...   \n",
       "2  Two-stage structural damage detection using fu...   \n",
       "3  A modular Decision Support System for optimum ...   \n",
       "4  Introduction of evidential contribution measur...   \n",
       "\n",
       "                                             Authors  Year  \\\n",
       "0                         Jian-Da Wu,Cheng-Kai Huang  2011   \n",
       "1                            Jung-Chi Pai,Fu-Ming Tu  2011   \n",
       "2         Shao-Fei Jiang,Chun-Ming Zhang,Shuai Zhang  2011   \n",
       "3  Kaveh Khalili Damghani,Soheil Sadi-Nezhad,M. B...  2011   \n",
       "4                     Malcolm J. Beynon,Rhys Andrews  2011   \n",
       "\n",
       "                Venue    Index References Abstract  \n",
       "0  Expert Syst. Appl.  1492668        NaN      NaN  \n",
       "1  Expert Syst. Appl.  1492669        NaN      NaN  \n",
       "2  Expert Syst. Appl.  1492654        NaN      NaN  \n",
       "3  Expert Syst. Appl.  1492655        NaN      NaN  \n",
       "4  Expert Syst. Appl.  1492656        NaN      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = df.sort_values(by=['Year'], ascending=False).reset_index(drop=True)\n",
    "sorted_df.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6849\n",
      "6897 / 1511035\n"
     ]
    }
   ],
   "source": [
    "# Select a subset of the data\n",
    "n_rows = 1000\n",
    "from_ids, to_ids = [], []\n",
    "cnt = 0\n",
    "for i, row in sorted_df.iterrows():\n",
    "    refs = row[\"References\"]\n",
    "    if pd.isna(refs):\n",
    "        continue\n",
    "    refs = refs.split(\", \")\n",
    "    for ref in refs:\n",
    "        from_ids.append(row[\"Index\"])\n",
    "        to_ids.append(int(ref))\n",
    "    cnt += 1\n",
    "    if cnt > n_rows:\n",
    "        break\n",
    "all_ids = list(set(from_ids + to_ids))\n",
    "print(len(from_ids))\n",
    "print(f\"{len(all_ids)} / {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = sorted(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_166038/820150632.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df[\"Index\"] = new_df[\"Index\"].map(new_id)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6897"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_id = {old: new for new, old in enumerate(all_ids)}\n",
    "new_df = df[df[\"Index\"].isin(all_ids)]\n",
    "new_df[\"Index\"] = new_df[\"Index\"].map(new_id)\n",
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_from_ids = [new_id[x] for x in from_ids]\n",
    "new_to_ids = [new_id[x] for x in to_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "\n",
    "g = dgl.graph((torch.tensor(new_from_ids), torch.tensor(new_to_ids)))\n",
    "g = dgl.to_bidirected(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "def get_embedding_bert(texts, model, tokenizer, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        inputs = tokenizer(texts[i:i+batch_size], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        outputs = model(**inputs)\n",
    "        embeddings.append(outputs.pooler_output)\n",
    "    return torch.cat(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "input_texts = [\n",
    "    \"what is the capital of China?\",\n",
    "    \"how to implement quick sort in python?\",\n",
    "    \"Beijing\",\n",
    "    \"sorting algorithms\"\n",
    "]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"thenlper/gte-small\")\n",
    "model = AutoModel.from_pretrained(\"thenlper/gte-small\")\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "def get_embedding(texts, model, tokenizer, batch_size=64):\n",
    "    outputs = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_inputs = tokenizer(batch_texts, max_length=512, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        batch_outputs = model(**batch_inputs)\n",
    "        batch_embeddings = average_pool(batch_outputs.last_hidden_state, batch_inputs['attention_mask'])\n",
    "        outputs.append(batch_embeddings)\n",
    "    return torch.cat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = new_df[\"Title\"].fillna(\"\") + \"\\n\" + new_df[\"Abstract\"].fillna(\"\")\n",
    "corpus_ids = new_df[\"Index\"].tolist()\n",
    "corpus = corpus.tolist()\n",
    "prompted_corpus = []\n",
    "for sen in corpus:\n",
    "    title, abstract = sen.split(\"\\n\")\n",
    "    title = title.strip()\n",
    "    abstract = abstract.strip()\n",
    "    if len(title) > 0 and len(abstract) > 0:\n",
    "        prompt = f\"Title: {title}\\nAbstract: {abstract}\\n\"\n",
    "    elif len(title) > 0:\n",
    "        prompt = f\"Title: {title}\\n\"\n",
    "    elif len(abstract) > 0:\n",
    "        prompt = f\"Abstract: {abstract}\\n\"\n",
    "    else:\n",
    "        raise ValueError(\"Both title and abstract are empty\")\n",
    "    prompted_corpus.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompted_corpus_dict = {\n",
    "    i: prompted_corpus[i] for i in range(len(prompted_corpus))\n",
    "}\n",
    "import json\n",
    "with open(\"prompted_corpus.json\", \"w\") as f:\n",
    "    json.dump(prompted_corpus_dict, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "prompts = json.load(open(\"prompted_corpus.json\"))\n",
    "# with open('extracted_prompts.npy', 'rb') as f:\n",
    "#     all_extracted = np.load(f)\n",
    "# print(all_extracted.shape)\n",
    "all_extracted = []\n",
    "texts = []\n",
    "for i in range(len(all_extracted), min(len(all_extracted) + 640, len(prompts))):\n",
    "    texts.append(prompts[str(i)])\n",
    "temp_extracted = get_embedding(texts, model, tokenizer)\n",
    "temp_extracted = temp_extracted.cpu().detach().numpy()\n",
    "all_extracted = np.concatenate([all_extracted, temp_extracted], axis=0)\n",
    "\n",
    "with open('extracted_prompts.npy', 'wb') as f:\n",
    "    np.save(f, all_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_features = get_embedding(prompted_corpus, model, tokenizer)\n",
    "node_features = get_embedding_bert(prompted_corpus, bert_model, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "node_features = torch.tensor(np.load(\"extracted_prompts.npy\"))\n",
    "# print(node_features.shape)\n",
    "g.ndata['feat'] = node_features\n",
    "from dgl.data.utils import save_graphs\n",
    "name =  \"citation_6897_384.dgl\"\n",
    "save_graphs(name, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
